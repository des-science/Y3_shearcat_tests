{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool,sharedctypes\n",
    "from functools import partial\n",
    "from contextlib import closing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import healpy as hp\n",
    "import h5py as h5\n",
    "import os\n",
    "import sys\n",
    "import skymapper as skm\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib\n",
    "import copy\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "colors = ['#601A4A', '#EE442F','#63ACBE']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from matplotlib import rc\n",
    "#rc('text', usetex=True)\n",
    "rc('font', family='serif')\n",
    "rc('font', size=11)\n",
    "fontsize='small'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/m/mgatti/.conda/envs/py3s/lib/python3.6/site-packages/ipykernel_launcher.py:62: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', 'T_err', 'covmat_0_1', 'covmat_1_1', 'covmat_2_2', 'e_1', 'e_2', 'flux_err_i', 'flux_err_r', 'flux_err_z', 'flux_i', 'flux_r', 'flux_z', 'size_ratio', 'snr', 'weight']\n",
      "using select_path for mask\n",
      "destest /global/cscratch1/sd/troxel/cats_des_y3/Y3_mastercat_03_31_20.h5 index/select 399263026 100208944\n",
      "end mask [     7390      7391      7393 ... 399243228 399243235 399243240] [ True  True  True ...  True  True  True]\n",
      "R11 not in sheared cols\n",
      "R11 not in sheared cols\n",
      "R11 not in sheared cols\n",
      "R11 not in sheared cols\n",
      "R22 not in sheared cols\n",
      "R22 not in sheared cols\n",
      "R22 not in sheared cols\n",
      "R22 not in sheared cols\n",
      "skipping sheared columns for e_1\n",
      "skipping sheared columns for e_1\n",
      "skipping sheared columns for e_1\n",
      "skipping sheared columns for e_1\n",
      "skipping sheared columns for e_2\n",
      "skipping sheared columns for e_2\n",
      "skipping sheared columns for e_2\n",
      "skipping sheared columns for e_2\n",
      "['bhat', 'cell_wide']\n",
      "----- e_1 ['e_1', 'e_2']\n",
      "Rs e_1 0.6735277671413801 0.009213749178185052\n",
      "0.7178247461393505 0.0 [32.7504844  41.16026567 44.41307    ... 40.2746443  45.48614938\n",
      " 11.63795655]\n",
      "----- e_2 ['e_1', 'e_2']\n",
      "Rs e_2 0.6744700947365396 0.009740859697198415\n",
      "0.719548101073125 0.0 [32.7504844  41.16026567 44.41307    ... 40.2746443  45.48614938\n",
      " 11.63795655]\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import destest\n",
    "import treecorr\n",
    "\n",
    "\n",
    "# basic dict props\n",
    "destest_dict_ = {\n",
    "    'output_exists' : True,\n",
    "    'use_mpi'       : False,\n",
    "    'source'        : 'hdf5',\n",
    "    'dg'            : 0.01\n",
    "    }\n",
    "\n",
    "# Populates a full destest yaml dict for each catalog selection based on the limited catalog input info provided in the common cats.yaml file\n",
    "def create_destest_yaml( params, name, cal_type, group, table, select_path ):\n",
    "    \"\"\"\n",
    "    Creates the input dictionary structure from a passed dictionary rather than reading froma yaml file.\n",
    "    \"\"\"\n",
    "\n",
    "    destest_dict = destest_dict_.copy()\n",
    "    destest_dict['load_cache'] = params['load_cache']\n",
    "    destest_dict['output'] = params['output']\n",
    "    destest_dict['name'] = name\n",
    "    destest_dict['filename'] = params['datafile']\n",
    "    destest_dict['param_file'] = params['param_file']\n",
    "    destest_dict['cal_type'] = cal_type\n",
    "    destest_dict['group'] = group\n",
    "    destest_dict['table'] = table\n",
    "    destest_dict['select_path'] = select_path\n",
    "    destest_dict['e'] = ['e_1','e_2']\n",
    "    destest_dict['Rg'] = ['R11','R22']\n",
    "    destest_dict['w'] = 'weight'\n",
    "\n",
    "    return destest_dict\n",
    "\n",
    "# Build selector (and calibrator) classes from destest for the catalog.\n",
    "def load_catalog(pipe_params, name, cal_type, group, table, select_path, inherit=None, return_calibrator=None):\n",
    "    \"\"\"\n",
    "    Loads data access and calibration classes from destest for a given yaml setup file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Input yaml file defining catalog\n",
    "    params = create_destest_yaml(pipe_params, name, cal_type, group, table, select_path)\n",
    "\n",
    "    # Load destest source class to manage access to file\n",
    "    source = destest.H5Source(params)\n",
    "\n",
    "    # Load destest selector class to manage access to data in a structured way\n",
    "    if inherit is None:\n",
    "        sel = destest.Selector(params,source)\n",
    "    else:\n",
    "        sel = destest.Selector(params,source,inherit=inherit)\n",
    "\n",
    "    # Load destest calibrator class to manage calibration of the catalog\n",
    "    if return_calibrator is not None:\n",
    "        cal = return_calibrator(params,sel)\n",
    "        return sel, cal\n",
    "    else:\n",
    "        return sel\n",
    "\n",
    "# Read yaml file that defines all the catalog selections used\n",
    "params = yaml.load(open('cats.yaml'))\n",
    "params['param_file'] = 'cats.yaml'\n",
    "\n",
    "# Source catalog\n",
    "source_selector, source_calibrator = load_catalog(\n",
    "    params, 'mcal', 'mcal', params['source_group'], params['source_table'], params['source_path'], return_calibrator=destest.MetaCalib)\n",
    "\n",
    "# Gold catalog\n",
    "gold_selector = load_catalog(\n",
    "    params, 'gold', 'mcal', params['gold_group'], params['gold_table'], params['gold_path'], inherit=source_selector)\n",
    "# BPZ (or DNF) catalog, depending on paths in cats.yaml file (exchange bpz and dnf)\n",
    "pz_selector = load_catalog(\n",
    "    params, 'pz', 'mcal', params['pz_group'], params['pz_table'], params['pz_path'], inherit=source_selector)\n",
    "\n",
    "\n",
    "R1,c,w = source_calibrator.calibrate('e_1') # Optionally pass an additional mask to use when calculating the selection response. The returned R1 is <Rg_1 + Rs_1>. To get an array of R's, use return_wRg=True to get [Rg_1+Rg_2]/2 for each object or return_wRgS=True to include the selection response. return_full=True returns the non-component-averaged version of the full response.\n",
    "print(R1,c,w)\n",
    "R2,c,w = source_calibrator.calibrate('e_2')\n",
    "print(R2,c,w)\n",
    "\n",
    "\n",
    "# Load ra,dec from gold catalog\n",
    "ra  = gold_selector.get_col('ra')[0]\n",
    "dec = gold_selector.get_col('dec')[0]\n",
    "\n",
    "# Get e1,e2 \n",
    "g1=source_selector.get_col('e_1')[0]\n",
    "g2=source_selector.get_col('e_2')[0]\n",
    "snr =source_selector.get_col('snr')[0]\n",
    "size_ratio =source_selector.get_col('size_ratio')[0]\n",
    "w = source_calibrator.calibrate('e_1',weight_only=True) # Optionally pass an additional mask to use when calculating the selection response. The returned R1 is <Rg_1 + Rs_1>. To get an array of R's, use return_wRg=True to get [Rg_1+Rg_2]/2 for each object or return_wRgS=True to include the selection response. return_full=True returns the non-component-averaged version of the full response.\n",
    "R_array = source_calibrator.calibrate('e_1',return_wRgS=True)\n",
    "\n",
    "g1 =(g1 - np.mean(g1*w)/np.mean(w))/R1\n",
    "g2 =(g2 - np.mean(g2*w)/np.mean(w))/R2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'numpy' from '/global/homes/m/mgatti/.conda/envs/py3s/lib/python3.6/site-packages/numpy/__init__.py'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/global/homes/m/mgatti/.conda/envs/py3s/lib/python3.6/site-packages/ipykernel_launcher.py:47: RuntimeWarning: invalid value encountered in true_divide\n",
      "/global/homes/m/mgatti/.conda/envs/py3s/lib/python3.6/site-packages/ipykernel_launcher.py:54: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'save_obj' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-db95c90437b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0mdict_maps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'n_eff'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_eff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0mdict_maps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mas_desy3'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmas_desy3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0msave_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'dict_maps'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdict_maps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'save_obj' is not defined"
     ]
    }
   ],
   "source": [
    "desy3_map = np.zeros(hp.nside2npix(nside))\n",
    "desy3_map_w = np.zeros(hp.nside2npix(nside))\n",
    "desy3_map_w2 = np.zeros(hp.nside2npix(nside))\n",
    "w_map = np.zeros(hp.nside2npix(nside))\n",
    "snr_map = np.zeros(hp.nside2npix(nside))\n",
    "snr_map_w = np.zeros(hp.nside2npix(nside))\n",
    "SR_map = np.zeros(hp.nside2npix(nside))\n",
    "SR_map_w = np.zeros(hp.nside2npix(nside))\n",
    "response_map_w = np.zeros(hp.nside2npix(nside))\n",
    "\n",
    "sum_we2_2 = np.zeros(hp.nside2npix(nside))\n",
    "sum_we2_1 = np.zeros(hp.nside2npix(nside))\n",
    "sum_w2 = np.zeros(hp.nside2npix(nside))\n",
    "sum_w = np.zeros(hp.nside2npix(nside))\n",
    "e1_map = np.zeros(hp.nside2npix(nside))\n",
    "e1_map_w = np.zeros(hp.nside2npix(nside))\n",
    "e2_map = np.zeros(hp.nside2npix(nside))\n",
    "e2_map_w = np.zeros(hp.nside2npix(nside))\n",
    "\n",
    "\n",
    "pix1 = convert_to_pix_coord(ra,dec, nside=nside)\n",
    "unique_pix1, idx1, idx_rep1 = np.unique(pix1, return_index=True, return_inverse=True)\n",
    "\n",
    "\n",
    "desy3_map[unique_pix1] += np.bincount(idx_rep1, weights=np.ones(len(pix1)))\n",
    "desy3_map_w[unique_pix1] += np.bincount(idx_rep1, weights=w)\n",
    "desy3_map_w2[unique_pix1] += np.bincount(idx_rep1, weights=w**2)\n",
    "w_map[unique_pix1] += np.bincount(idx_rep1, weights=w)\n",
    "snr_map_w[unique_pix1] += np.bincount(idx_rep1, weights=snr*w)\n",
    "snr_map[unique_pix1] += np.bincount(idx_rep1, weights=snr)\n",
    "SR_map[unique_pix1] += np.bincount(idx_rep1, weights=size_ratio)\n",
    "SR_map_w [unique_pix1] += np.bincount(idx_rep1, weights=(size_ratio*w))\n",
    "sum_we2_2[unique_pix1] += np.bincount(idx_rep1, weights=(w*g2)**2)\n",
    "sum_we2_1[unique_pix1] += np.bincount(idx_rep1, weights=(w*g1)**2)\n",
    "sum_w2[unique_pix1] += np.bincount(idx_rep1, weights=(w)**2)\n",
    "sum_w[unique_pix1] += np.bincount(idx_rep1, weights=(w))\n",
    "response_map_w[unique_pix1] += np.bincount(idx_rep1, weights=R_array)\n",
    "\n",
    "e1_map_w[unique_pix1] += np.bincount(idx_rep1, weights=g1*w)\n",
    "e2_map_w[unique_pix1] += np.bincount(idx_rep1, weights=g2*w)\n",
    "e1_map[unique_pix1] += np.bincount(idx_rep1, weights=g1)\n",
    "e2_map[unique_pix1] += np.bincount(idx_rep1, weights=g2)\n",
    "\n",
    "\n",
    "mas_desy3 = desy3_map!=0.\n",
    "n_eff = desy3_map/(hp.pixelfunc.nside2pixarea(nside,degrees=True)*(60*60)) #/R_ave\n",
    "n_eff_w = desy3_map_w**2/desy3_map_w2/(hp.pixelfunc.nside2pixarea(nside,degrees=True)*(60*60)) #/R_ave\n",
    "w_map[mas_desy3] = w_map[mas_desy3]/desy3_map[mas_desy3]\n",
    "snr_map[mas_desy3] = snr_map[mas_desy3]/desy3_map[mas_desy3]\n",
    "snr_map_w[mas_desy3] = snr_map_w[mas_desy3]/desy3_map_w[mas_desy3]\n",
    "SR_map[mas_desy3] = SR_map[mas_desy3]/desy3_map[mas_desy3]\n",
    "SR_map_w[mas_desy3] = SR_map_w[mas_desy3]/desy3_map_w[mas_desy3]\n",
    "response_map_w[mas_desy3]=response_map_w[mas_desy3]/desy3_map_w[mas_desy3]\n",
    "sig_e = np.sqrt((sum_we2_1/sum_w**2+sum_we2_2/sum_w**2)*(sum_w**2/sum_w2)/2.)\n",
    "e1_map_w[mas_desy3]=e1_map_w[mas_desy3]/desy3_map_w[mas_desy3]\n",
    "e2_map_w[mas_desy3]=e2_map_w[mas_desy3]/desy3_map_w[mas_desy3]\n",
    "e1_map[mas_desy3]  =e1_map[mas_desy3]/desy3_map[mas_desy3]\n",
    "e2_map[mas_desy3]  =e2_map[mas_desy3]/desy3_map[mas_desy3]\n",
    "\n",
    "\n",
    "\n",
    "dict_maps = dict()\n",
    "dict_maps['e2_map']=e2_map\n",
    "dict_maps['e1_map']=e1_map\n",
    "dict_maps['e1_map_w']=e1_map_w\n",
    "dict_maps['e2_map_w']=e2_map_w\n",
    "dict_maps['sig_e']=sig_e\n",
    "dict_maps['response_map_w']=response_map_w\n",
    "dict_maps['SR_map_w']=SR_map_w\n",
    "dict_maps['SR_map']=SR_map\n",
    "dict_maps['w_map']=w_map\n",
    "dict_maps['snr_map_w']=snr_map_w\n",
    "dict_maps['snr_map']=snr_map\n",
    "dict_maps['n_eff_w']=n_eff_w\n",
    "dict_maps['n_eff']=n_eff\n",
    "dict_maps['mas_desy3']=mas_desy3\n",
    "import pickle\n",
    "def save_obj( name,obj ):\n",
    "    with open( name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "save_obj('dict_maps',dict_maps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ[\"PROJ_LIB\"] = \"C:\\\\Utilities\\\\Python\\\\Anaconda\\\\Library\\\\share\"\n",
    "import pylab as plt\n",
    "import skymap\n",
    "from skymap import Skymap,McBrydeSkymap,OrthoSkymap\n",
    "\n",
    "import healpy as hp\n",
    "import fitsio\n",
    "import numpy as np\n",
    "import skymap\n",
    "from skymap.survey import DESSkymap\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "nside=1024\n",
    "\n",
    "\n",
    "import pickle\n",
    "colors = ['#601A4A', '#EE442F','#63ACBE']\n",
    "\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "\n",
    "def load_obj(name):\n",
    "    \n",
    "        try:\n",
    "            with open(name + '.pkl', 'rb') as f:\n",
    "                return pickle.load(f)#, encoding='latin1')\n",
    "        except:\n",
    "            with open(name + '.pkl', 'rb') as f:\n",
    "                return pickle.load(f, encoding='latin1')\n",
    "            \n",
    "            \n",
    "def make_plot(mapp,pix_mask,savedir,title,xsize=5000,smooth=10.0/60,smoothing=True,vmin=-0.01,vmax=0.01):\n",
    "    fig = plt.figure(figsize=(9,6))\n",
    "\n",
    "\n",
    "    smap = skymap.DESSkymap()\n",
    "    ax=plt.gca()\n",
    "    \n",
    "\n",
    "    \n",
    "    plt.sca(ax)\n",
    "    if smoothing:\n",
    "        smap.draw_hpxmap(mapp[pix_mask],pix_mask,nside,cmap=cmap,vmin=vmin,vmax=vmax,xsize=xsize,smooth=smooth) #\n",
    "    else:\n",
    "        smap.draw_hpxmap(mapp[pix_mask],pix_mask,nside,cmap=cmap,vmin=vmin,vmax=vmax,xsize=xsize) #\n",
    "    smap.draw_inset_colorbar(ticks=[vmin,vmax],format='%.2f',fontsize=10,bbox_to_anchor=(-0.05,-0.0,1,1))\n",
    "    \n",
    "    plt.title(title,y=1.08,fontsize=18)\n",
    "    plt.savefig(savedir,bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "des_c1_cmap = LinearSegmentedColormap.from_list('mycmap', list(zip(np.linspace(0,1,2), ['#ffffff', colors[0]])))\n",
    "\n",
    "cmap = des_c1_cmap\n",
    "pixels = np.arange(hp.nside2npix(nside))\n",
    "pix_mask =pixels[dictt['mas_desy3']]\n",
    "\n",
    "\n",
    "\n",
    "make_plot((dictt['n_eff_w']),pix_mask,title = 'n_eff (H12, with weights)',vmin = 3., vmax = 8.,savedir='./figures_shearcat/neffw.pdf')\n",
    "make_plot((dictt['sig_e']),pix_mask,title ='sigma_e (with weights)',vmin = 0.25, vmax = 0.3,savedir='./figures_shearcat/sige.pdf')\n",
    "make_plot((dictt['response_map_w']),pix_mask,title ='Response (with weights)',vmin = 0.65, vmax = 0.75,savedir='./figures_shearcat/responsew.pdf')\n",
    "make_plot(np.log10(dictt['snr_map']+1),pix_mask,title ='log10 snr (no weights)',vmin = 1., vmax = 2,savedir='./figures_shearcat/snr.pdf')\n",
    "make_plot((dictt['SR_map']),pix_mask,title ='size ratio (no weights)',vmin = 0.5, vmax = 2.5,savedir='./figures_shearcat/SR.pdf')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3s",
   "language": "python",
   "name": "py3s"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
